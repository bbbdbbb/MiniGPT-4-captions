# MiniGPT-4-captions

## Introduce
Our project leverages [MiniGPT-v2](https://github.com/Vision-CAIR/MiniGPT-4) and custom scripts to address the challenge of dataset annotation by automatically generating captions for images. By utilizing this powerful language model, we aim to alleviate the time-consuming and labor-intensive task of manually annotating large datasets.  

Join us on this project as we harness the capabilities of MiniGPT-v2 scripts to revolutionize dataset annotation and advance the field of computer vision. Together, we can overcome the challenges of dataset annotation and explore the potential of automated image caption generation.  

## Getting Started
### Installation
**1. Prepare the code and the environment**  
You can git clone MiniGPT-v2 repository or our repository, creating a conda virtual environment according to official instructions.
```bash
# git clone https://github.com/Vision-CAIR/MiniGPT-4.git

# To avoid unnecessary code, it is recommended to clone our repository
git clone https://github.com/bbbdbbb/MiniGPT-4-captions.git
cd MiniGPT-4
conda env create -f environment.yml
conda activate minigptv
```